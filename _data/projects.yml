- title: Unsupervised learning methods for large-scale, multi-trial neural data
  description: >
    A common paradigm in systems neuroscience is to simultaneously record the
    activity of many neurons over repeated experimental trials (e.g., multiple
    presentations of a sensory stimulus, or a repeated motor action). The resulting
    datasets can be very large, potentially containing thousands of
    neurons over thousands of trials. I'm interested in finding general-purpose
    statistical approaches for understanding datasets of this form. 
- items:
  - name: Tensor Decomposition
    icon: file-pdf-o
    url: https://pyramidal.stanford.edu/publications/Williams2018_Neuron.pdf
    description: >
      In collaboration with experimental groups headed by 
      <a href="https://shenoy.people.stanford.edu/overview" target="_blank">Krishna Shenoy</a>
      and 
      <a href="https://pyramidal.stanford.edu/" target="_blank">Mark Schnitzer</a>
      we demonstrate how to extract functional neural subpopulations across learning
      and changing environments
  - name: Time Warping
    icon: file-pdf-o
    url: /pdf/2020_timewarp.pdf
    description: >
      In collaboration with
      <a href="https://med.nyu.edu/faculty/dmitry-rinberg" target="_blank">Rinberg</a>,
      <a href="https://shenoy.people.stanford.edu/overview" target="_blank">Shenoy</a>,
      and 
      <a href="https://olveczkylab.oeb.harvard.edu/" target="_blank">&Ouml;lveczky</a>,
      labs we demonstrate how to discover precisely timed neural spike patterns in
      the presence of trial-to-trial jitter and other temporal misalignments.
  - name: Tutorial video
    icon: youtube-square
    url: https://www.youtube.com/watch?v=hmmnRF66hOA
    description: >
      In this talk (given at MIT, 2017) I give a high level overview of some of the research
      cited above.

- title: Automated segmentation and detection of motifs in high-dimensional time series
  description: >
    Trial-structured data (described above) are convienent for data analysis &mdash; in particular,
    if neural dynamics on different trials follow a similar (though not identical) trajectory,
    we can build a model that isolates this structure while discarding the remaining "noise"
    (for lack of a better term). A more challenging problem is how to extract scientifically
    interpretable features from unstructured neural and behavioral data streams (e.g. during
    unconstrained natural behaviors). To address this, I have developed some models that extract
    temporal motifs or "pseudo-trials" from raw time series.

- items:
  - name: Convolutional NMF
    icon: file-pdf-o
    url: https://doi.org/10.7554/eLife.38471
    description: >
      Led by <a href="https://emackev.github.io/" target="_blank">Emily Mackevicius</a>
      and <a href="http://web.mit.edu/abahle/www/" target="_blank">Andrew Bahle</a>, we
      repurposed a convolutional nonnegative matrix factorization (convNMF) model (see
      <a href="https://doi.org/10.1109/TASL.2006.876726" target="_blank">Smaragdis, 2007</a>)
      to extract sequential firing patterns in songbirds and rats from unannotated neural population
      recordings. Thanks also to <a href="https://feelaboratory.org/" target="_blank">Michale Fee</a>
      and <a href="https://goldmanlab.faculty.ucdavis.edu/" target="_blank">Mark Goldman</a>
      for guidance and oversight!
  - name: A Point Process Framework for Sequence Detection
    icon: file-pdf-o
    url: https://arxiv.org/pdf/2010.04875.pdf
    description: >
      Here we reformulate the convNMF model for spike train data, and in doing so draw a connection to
      <a href="https://www.jstor.org/stable/2983905" target="_blank">Neyman-Scott point process</a>
      models. We find that this model is more capable of handling noise in low firing rate regimes
      than the original convNMF model. We also get better quantification of model uncertainty by performing
      model inference in a fully Bayesian manner.
